"""Flask application for OLASIS 4.0.

This module defines a small web server that powers the OLA           """Perform a combined search across OpenAlex and ORCID.

        Expects a ``q`` query parameter containing the user's search
        string, and optional ``page`` parameter for pagination.
        Returns a JSON object with two lists: ``articles`` and
        ``specialists``, plus pagination metadata.  Each article is represented as a dictionary
        containing the keys ``title``, ``authors``, ``year``, ``openalex_id``,
        ``doi`` and ``url``.  Each specialist contains ``orcid``, ``given_names``,
        ``family_names``, ``full_name`` and ``profile_url``.
        """
        query: str = request.args.get("q", "").strip()
        if not query:
            return {"error": "No search query provided."}, 400
            
        # Pagination parameters
        page = max(1, int(request.args.get("page", 1)))
        per_page = 6  # Fixed at 6 items per page
        
        # Get more results to support pagination (we'll slice them client-side for better performance)
        total_results_to_fetch = 50
        articles = search_articles(query, per_page=total_results_to_fetch)
        specialists = search_specialists(query, rows=total_results_to_fetch)
        
        # Calculate pagination for articles
        articles_start = (page - 1) * per_page
        articles_end = articles_start + per_page
        articles_page = articles[articles_start:articles_end]
        articles_total = len(articles)
        articles_total_pages = (articles_total + per_page - 1) // per_page
        
        # Calculate pagination for specialists
        specialists_start = (page - 1) * per_page
        specialists_end = specialists_start + per_page
        specialists_page = specialists[specialists_start:specialists_end]
        specialists_total = len(specialists)
        specialists_total_pages = (specialists_total + per_page - 1) // per_page
        
        return {
            "articles": articles_page,
            "specialists": specialists_page,
            "pagination": {
                "current_page": page,
                "per_page": per_page,
                "articles": {
                    "total": articles_total,
                    "total_pages": articles_total_pages,
                    "has_next": page < articles_total_pages,
                    "has_prev": page > 1
                },
                "specialists": {
                    "total": specialists_total,
                    "total_pages": specialists_total_pages,
                    "has_next": page < specialists_total_pages,
                    "has_prev": page > 1
                }
            }
        }, 200q`` query parameter containing the user's search
        string.  Returns a JSON object with two lists: ``articles`` and
        ``specialists``.  Each article is represented as a dictionary
        containing the keys ``title``, ``authors``, ``year``, ``openalex_id``,
        ``doi`` and ``url``.  Each specialist contains ``orcid``, ``given_names``,
        ``family_names``, ``full_name`` and ``profile_url``.0
interface.  It exposes three routes:

* ``/`` – serves the main HTML page.  The front‑end layout and styling
  are defined in ``templates/index.html`` and must not be changed
  programmatically.  The page includes all of the original CSS from
  ``Olasis4.html`` so that the visual look and feel remains the same.

* ``/api/search`` – returns search results from OpenAlex and ORCID in
  JSON format.  The front‑end issues a GET request to this endpoint
  whenever the user submits a search.  Two lists are returned: one
  containing article metadata (title, authors, year, DOI and OpenAlex ID)
  and another containing specialist profiles (ORCID identifier, name and
  profile URL).

* ``/api/chat`` – accepts a user message via POST and returns a
  response generated by Google’s Gemini generative AI.  The back‑end
  integrates with the ``olasis.Chatbot`` wrapper which reads the API
  key from the ``GOOGLE_API_KEY`` environment variable.  If the key is
  missing or the ``google‑genai`` package is not installed, the
  chatbot falls back to an informative error message.

Usage
-----

Install the dependencies listed in ``requirements.txt`` and set
``GOOGLE_API_KEY`` in your environment.  Then run

::

    python app.py

The server will start on port 5000 by default.  Visit
``http://localhost:5000`` in your browser to use the application.
"""

from __future__ import annotations

import os
from flask import Flask, jsonify, render_template, request
from dotenv import load_dotenv

from olasis import Chatbot, search_articles, search_specialists

# Carregar variáveis de ambiente do arquivo .env
load_dotenv()


def create_app() -> Flask:
    """Factory to create and configure the Flask application.

    Returns
    -------
    Flask
        A configured Flask application instance.
    """
    app = Flask(
        __name__,
        template_folder="templates",
        static_folder="static",
    )
    
    # Configuração para produção
    app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'olasis4-secret-key-change-in-production')
    
    # Melhor tratamento de erros
    @app.errorhandler(404)
    def not_found(error):
        return render_template("index.html"), 404
    
    @app.errorhandler(500)
    def internal_error(error):
        return jsonify({"error": "Internal server error"}), 500

    # Initialise the chatbot once at start‑up.  The API key will be read
    # from the environment variable GOOGLE_API_KEY.  If the key is not
    # provided the Chatbot will respond with an error message.
    chatbot = Chatbot(api_key=os.getenv("GOOGLE_API_KEY"), model="gemini-2.5-flash")

    @app.route("/")
    def index() -> str:
        """Render the main search page.

        The HTML template is a verbatim copy of the original
        ``Olasis4.html`` file with only minor additions to include
        external JavaScript.  Any changes to the look and feel should be
        done in the template, not in Python.
        """
        return render_template("index.html")

    @app.route("/api/search")
    def api_search() -> tuple[dict[str, object], int] | tuple[dict[str, str], int]:
        """Perform a combined search across OpenAlex and ORCID.

        Expects a ``q`` query parameter containing the user’s search
        string.  Returns a JSON object with two lists: ``articles`` and
        ``specialists``.  Each article is represented as a dictionary
        containing the keys ``title``, ``authors``, ``year``, ``openalex_id``
        and ``doi``.  Each specialist contains ``orcid``, ``given_names``,
        ``family_names``, ``full_name`` and ``profile_url``.
        """
        query: str = request.args.get("q", "").strip()
        if not query:
            return {"error": "No search query provided."}, 400
        # Limit the number of results to show more comprehensive results.
        # The underlying modules cap values internally as well.
        articles = search_articles(query, per_page=50)
        specialists = search_specialists(query, rows=50)
        return {"articles": articles, "specialists": specialists}, 200

    @app.route("/api/chat", methods=["POST"])
    def api_chat() -> tuple[dict[str, str], int]:
        """Generate a chatbot response to the user’s message.

        The request body must be JSON with a ``message`` key.  A 400
        status code will be returned if the message is missing or
        blank.  Otherwise the Gemini API is queried via the Chatbot
        wrapper and the resulting text is returned in the ``response``
        field.
        """
        data = request.get_json(silent=True) or {}
        message: str = (data.get("message") or "").strip()
        if not message:
            return {"response": "Por favor, proporcione un mensaje."}, 400
        # Ask the chatbot for a response.  If the API call fails the
        # wrapper will return an informative fallback message.
        reply = chatbot.ask(message)
        return {"response": reply}, 200

    return app


# Criar a instância da aplicação para o gunicorn
app = create_app()


if __name__ == "__main__":
    # When executed directly, run the application using Flask's dev server.
    # In production, gunicorn will use the 'app' instance created above.
    port = int(os.getenv("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=False)